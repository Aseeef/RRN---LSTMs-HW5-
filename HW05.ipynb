{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 505 Homework 05:  Recurrent Neural Networks\n",
    "\n",
    "#### Due Friday  11/17 at midnight (1 minute after 11:59 pm) in Gradescope (with a grace period of 6 hours)\n",
    "#### You may submit the homework up to 24 hours late (with the same grace period) for a penalty of 10%. \n",
    "\n",
    "All homeworks will be scored with a maximum of 100 points; point values are given\n",
    "for individual problems, and if parts of problems do not have point values given, they\n",
    "will be counted equally toward the total for that problem. \n",
    "\n",
    "Note: This homework is a bit different from the first four in this class in that in some parts we are specified **what** you need to do for your solutions, but much less of the **how** you write the details of the code. There are three reasons for this:\n",
    "\n",
    "- In a graduate level CS class, after four homeworks and two months of lectures, you should be well-equipped to work out the coding issues for yourself, and in general, going forward, this is how you will solve the kinds of problems presented here; \n",
    "- Suggestions for resources (mostly ML blogs) will be suggested; there are many resources, but these are from bloggers that I trust and have used in the past;\n",
    "- I am expecting that you will make good use of chatGPT for help with the details of syntax and low-level organization of your code. There is often nothing very stimulating or informative about precisely what is the syntax needed for a particular kind of layer in a network, and rather than poke around on StackOverflow, chatGPT is particularly good at summarizing existing approaches to ML coding tasks. \n",
    "\n",
    "#### Submission Instructions\n",
    "\n",
    "You must complete the homework by editing <b>this notebook</b> and submitting the following two files in Gradescope by the due date and time:\n",
    "\n",
    "  - A file <code>HW05.ipynb</code> (be sure to select <code>Kernel -> Restart and Run All</code> before you submit, to make sure everything works); and\n",
    "  - A file <code>HW05.pdf</code> created from the previous.\n",
    "  \n",
    "  For best results obtaining a clean PDF file on the Mac, select <code>File -> Print Review</code> from the Jupyter window, then choose <code>File-> Print</code> in your browser and then <code>Save as PDF</code>.  Something  similar should be possible on a Windows machine -- just make sure it is readable and no cell contents have been cut off. Make it easy to grade!\n",
    "  \n",
    "The date and time of your submission is the last file you submitted, so if your IPYNB file is submitted on time, but your PDF is late, then your submission is late. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborators (5 pts)\n",
    "\n",
    "Describe briefly but precisely\n",
    "\n",
    "1. Any persons you discussed this homework with and the nature of the discussion;\n",
    "2. Any online resources you consulted and what information you got from those resources; and\n",
    "3. Any AI agents (such as chatGPT or CoPilot) or other applications you used to complete the homework, and the nature of the help you received. \n",
    "\n",
    "A few brief sentences is all that I am looking for here. \n",
    "\n",
    "    <Your answer here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.269052900Z",
     "start_time": "2023-11-21T01:35:25.544701700Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import shuffle, seed, choice\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg, brown\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.270081800Z",
     "start_time": "2023-11-21T01:35:29.269052900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Dict\n",
    "from typing import Any\n",
    "from typing import Union\n",
    "from typing import DefaultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.271064300Z",
     "start_time": "2023-11-21T01:35:29.270081800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains some helpful methods to dump notebook variables\n",
    "to a file so you don't have to rerun expensive computations every\n",
    "time.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "def does_var_exists(var_name: str) -> bool:\n",
    "    return os.path.isfile(F'./data/pickle/{var_name}.pkl')\n",
    "\n",
    "def dump_var(var_name: str, obj) -> None:\n",
    "    with open(F'./data/pickle/{var_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "def load_var(var_name: str) -> Union[None, object]:\n",
    "    if not does_var_exists(var_name):\n",
    "        return None\n",
    "    with open(F'./data/pickle/{var_name}.pkl', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.271064300Z",
     "start_time": "2023-11-21T01:35:29.270081800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dirs where I'll be storing my data\n",
    "os.makedirs('./data/glove', exist_ok=True)\n",
    "os.makedirs('./data/java', exist_ok=True)\n",
    "os.makedirs('./data/pickle', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One:  Character-Level Generative Model (20 pts)\n",
    "\n",
    "A basic character-level model has been provided on the class web site in the row for Lecture 14: \n",
    "<a href=\"https://www.cs.bu.edu/fac/snyder/cs505/CharacterLevelLSTM.ipynb\">IPYNB</a>. Your first step is to download this and run it in Colab (or download the data file, which is in the CS 505 Data Directory and also linked on the web site, and run it on your local machine) and understand all its various features. Most of it is straight-forward at this point in the course, but the definition of the model is a bit messy, and you will need to read about LSTM layers in the Pytorch documents to really understand what it is doing and what the hyperparameters mean. \n",
    "\n",
    "Also take a look at the article \"The Unreasonable Effectiveness of Recurrent Neural Networks\" linked with lecture 14. \n",
    "\n",
    "For this problem, you will run this code on a dataset consisting of Java code files, which has been uploaded to the CS 505 Data Directory and also to the class web site: <a href=\"https://www.cs.bu.edu/fac/snyder/cs505/JavaFiles/\">DIR</a>  Select some number of these files and concatenate them into one long text file, such that you have approximately 10-20K characters (if you have trouble running out of RAM you can use fewer, but try to get at least 10K). \n",
    "\n",
    "You will run the character-level model on this dataset. You may either cut and paste code into this notebook, or submit the file with your changes and output along with this notebook to Gradescope.\n",
    "\n",
    "Your task is to get a character-level model that has not simply memorized the Java text file by overfitting, and does not do much other than spit out random characters (underfitting).  You will get the former if you simply run it for many epochs without any changes to the hyperparameters; you will get the latter if you run it only a few epochs. \n",
    "\n",
    "You should experiment with different hyperparameters, which in the notebook are indicated\n",
    "by \n",
    "\n",
    "          <== something to play with\n",
    "\n",
    "and try to get a model that seems to recognize typical Java syntax such as comments, matching parentheses, expressions, assignments, and formatting, but is not just repeating\n",
    "exact text from the data file. Clearly, the number of epochs plays a crucial role, but I also want you to\n",
    "experiment with the various hyperparameters to try to avoid overfitting. See my lectures on T 10/31 and Th 11/2 (recorded and on my YT channel) for the background to this.\n",
    "\n",
    "Note that the code you will work from does not use validation and testing sets, nor does it calculate the accuracy, but only tracks the loss. The nature of the data sets for character-level models does not seem to lend itself to accuracy metrics, but you may wish to try this -- I have not found it to be useful, but have simply focussed on the output and \"eyeballed\" the results to determine how much they have generalized\n",
    "from the data. \n",
    "\n",
    "Submit your notebook(s) to Gradescope as usual, and also provide a summary of your results in the next cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.276057700Z",
     "start_time": "2023-11-21T01:35:29.270081800Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the java sources\n",
    "java_source_list = []\n",
    "for java_file in os.listdir('./data/java/'):\n",
    "    with open('./data/java/' + java_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        java_source_list += lines\n",
    "\n",
    "java_source_text = '\\n'.join(java_source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.282468400Z",
     "start_time": "2023-11-21T01:35:29.277057800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 175818 characters long.\n",
      "First 200 characters: /* File: RecursiveGraphics.java\n",
      "\n",
      " * Author: \n",
      "\n",
      " * Date: \n",
      "\n",
      " * Purpose: This is the template for PS5, Problem 6\n",
      "\n",
      " */\n",
      "\n",
      "\n",
      "\n",
      "import java.awt.Color;\n",
      "\n",
      "import java.awt.Canvas;\n",
      "\n",
      "import java .awt.Graphics;\n",
      "\n",
      "import\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text is {len(java_source_text)} characters long.\")\n",
    "print(f\"First 200 characters: {java_source_text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.291530900Z",
     "start_time": "2023-11-21T01:35:29.286490400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do some cleaning\n",
    "cleaned_java_source_text = java_source_text\n",
    "# remove double new lines\n",
    "cleaned_java_source_text = re.sub(\"\\n\\n\", \"\\n\", cleaned_java_source_text)\n",
    "# remove lines with only whitespace\n",
    "cleaned_java_source_text = re.sub(r'^\\s*$', \"\", cleaned_java_source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.360034200Z",
     "start_time": "2023-11-21T01:35:29.293512Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 200 characters (cleaned): /* File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Problem 6\n",
      " */\n",
      "\n",
      "import java.awt.Color;\n",
      "import java.awt.Canvas;\n",
      "import java .awt.Graphics;\n",
      "import javax.sw\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 200 characters (cleaned): {cleaned_java_source_text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.372035100Z",
     "start_time": "2023-11-21T01:35:29.303533800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93 characters in the text.\n",
      "Character set: ['\\t', '\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}'].\n"
     ]
    }
   ],
   "source": [
    "chars_in_text = sorted(list(set(cleaned_java_source_text)))\n",
    "num_chars = len(chars_in_text)\n",
    "\n",
    "print(f'There are {num_chars} characters in the text.')\n",
    "print(f'Character set: {chars_in_text}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.372035100Z",
     "start_time": "2023-11-21T01:35:29.310039700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HYPER PARAMETERS HERE\n",
    "sample_len = 100 # <== something to play with\n",
    "batch_size = 128\n",
    "model_dropout=0.0\n",
    "hidden_dim_size = 256\n",
    "n_layers_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.373039100Z",
     "start_time": "2023-11-21T01:35:29.360034200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create functions mapping characters to integers and back\n",
    "\n",
    "def char2int(c):\n",
    "    return chars_in_text.index(c)\n",
    "\n",
    "def int2char(i):\n",
    "    return chars_in_text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.452902Z",
     "start_time": "2023-11-21T01:35:29.399048400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      "/* File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Pro\n",
      "Target sequence:\n",
      "* File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Prob\n",
      "\n",
      "Input sequence:\n",
      "* File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Prob\n",
      "Target sequence:\n",
      " File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Probl\n",
      "\n",
      "Input sequence:\n",
      " File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Probl\n",
      "Target sequence:\n",
      "File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Proble\n",
      "\n",
      "Input sequence:\n",
      "File: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Proble\n",
      "Target sequence:\n",
      "ile: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Problem\n",
      "\n",
      "Input sequence:\n",
      "ile: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Problem\n",
      "Target sequence:\n",
      "le: RecursiveGraphics.java\n",
      " * Author: \n",
      " * Date: \n",
      " * Purpose: This is the template for PS5, Problem \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating lists that will hold our input and target sample sequences\n",
    "\n",
    "input_seq_chars = []\n",
    "target_seq_chars = []\n",
    "\n",
    "for k in range(len(cleaned_java_source_text)-sample_len+1):\n",
    "\n",
    "    # Remove last character for input sequence\n",
    "    input_seq_chars.append(cleaned_java_source_text[k:k+sample_len-1])\n",
    "\n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq_chars.append(cleaned_java_source_text[k+1:k+sample_len])\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Input sequence:\\n{input_seq_chars[i]}')\n",
    "    print(f'Target sequence:\\n{target_seq_chars[i]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:35:29.474724400Z",
     "start_time": "2023-11-21T01:35:29.436888100Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert an integer into a one-hot encoding of the given size (= number of characters)\n",
    "def int2OneHot(X,size):\n",
    "\n",
    "    def int2OneHot1(x,size=10):\n",
    "        tmp = np.zeros(size)\n",
    "        tmp[int(x)] = 1.0\n",
    "        return tmp\n",
    "\n",
    "    return np.array([ int2OneHot1(x, size) for x in X ]).astype('double')\n",
    "\n",
    "# do the same thing, but for a list/array of integers\n",
    "def seq2OneHot(seq,size):\n",
    "    return np.array([ int2OneHot(x, size) for x in seq ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:08.030927Z",
     "start_time": "2023-11-21T01:35:29.463870700Z"
    }
   },
   "outputs": [],
   "source": [
    "input_seq = []\n",
    "for i in range(len(input_seq_chars)):\n",
    "    input_seq.append( [char2int(ch) for ch in input_seq_chars[i]])\n",
    "input_seq = seq2OneHot(input_seq,size=num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:43.232062800Z",
     "start_time": "2023-11-21T01:36:08.071407700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_seq = []\n",
    "for i in range(len(input_seq_chars)):\n",
    "    target_seq.append([char2int(ch) for ch in target_seq_chars[i]])\n",
    "target_seq = seq2OneHot(target_seq,size=num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:43.239061300Z",
     "start_time": "2023-11-21T01:36:43.233063400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (170475, 99, 93)\n",
      "target shape: (170475, 99, 93)\n"
     ]
    }
   ],
   "source": [
    "print('input shape:', input_seq.shape)\n",
    "print('target shape:', target_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:55.361718700Z",
     "start_time": "2023-11-21T01:36:43.240062500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_seq = torch.Tensor(input_seq).type(torch.DoubleTensor)\n",
    "target_seq = torch.Tensor(target_seq).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:55.372749600Z",
     "start_time": "2023-11-21T01:36:55.364715800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Basic_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # return a pair x,y at the index idx in the data set\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "ds = Basic_Dataset(input_seq,target_seq)\n",
    "ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:55.380723700Z",
     "start_time": "2023-11-21T01:36:55.374759200Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:55.388240400Z",
     "start_time": "2023-11-21T01:36:55.382731500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:55.433192100Z",
     "start_time": "2023-11-21T01:36:55.392830200Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, dropout):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers,dropout=dropout,batch_first=True)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        hidden_state_size = x.size(0)\n",
    "\n",
    "        x = x.to(torch.double)\n",
    "\n",
    "        h0 = torch.zeros(self.n_layers,hidden_state_size,self.hidden_dim).double().to(device)\n",
    "        c0 = torch.zeros(self.n_layers,hidden_state_size,self.hidden_dim).double().to(device)\n",
    "\n",
    "        self.lstm = self.lstm.double()\n",
    "\n",
    "        self.fc1 = self.fc1.double()\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, (hx,cx) = self.lstm(x, (h0,c0))\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:36:57.704524600Z",
     "start_time": "2023-11-21T01:36:55.433192100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (lstm): LSTM(93, 256, batch_first=True)\n",
      "  (fc1): Linear(in_features=256, out_features=93, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "\n",
    "model = Model(input_size=num_chars, output_size=num_chars, hidden_dim=hidden_dim_size, n_layers=n_layers_count,dropout=model_dropout)\n",
    "\n",
    "print(model)\n",
    "\n",
    "model = model.double().to(device)\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:05.396788Z",
     "start_time": "2023-11-21T02:03:16.676861400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:48<00:00, 34.87s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    for input_seq_batch,target_seq_batch in data_loader:\n",
    "        input_seq_batch = input_seq_batch.to(device)\n",
    "        target_seq_batch = target_seq_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target_seq_hat = model(input_seq_batch)\n",
    "        loss = loss_fn(target_seq_hat,target_seq_batch.view(-1,num_chars))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:05.576341700Z",
     "start_time": "2023-11-21T02:09:05.377787100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1469d408e9e8>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:05.586342200Z",
     "start_time": "2023-11-21T02:09:05.580342500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of softmax with temperature.\n",
      "distribution: [0.1, 0.3, 0.6]\n",
      "[1.9287498479637375e-22, 9.3576229688393e-14, 0.9999999999999064]\n",
      "[0.006377460922442302, 0.04712341652466416, 0.9464991225528936]\n",
      "[0.06289001324586753, 0.1709527801977903, 0.7661572065563421]\n",
      "[0.12132647558421489, 0.23631170657656433, 0.6423618178392208]\n",
      "[0.2583896517379799, 0.3155978333128144, 0.4260125149492058]\n",
      "[0.3255767455856355, 0.3321538321280155, 0.3422694222863489]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def softmax_with_temperature(vec, temperature):\n",
    "    sum_exp = sum(math.exp(x/temperature) for x in vec)\n",
    "    return [math.exp(x/temperature)/sum_exp for x in vec]\n",
    "\n",
    "print(\"Example of softmax with temperature.\")\n",
    "dist = [0.1, 0.3, 0.6]\n",
    "print('distribution:',dist)\n",
    "print(softmax_with_temperature(dist,0.01))\n",
    "print(softmax_with_temperature(dist,0.1))\n",
    "print(softmax_with_temperature(dist,0.2))\n",
    "print(softmax_with_temperature(dist,0.3))\n",
    "print(softmax_with_temperature(dist,1))\n",
    "print(softmax_with_temperature(dist,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:05.650515500Z",
     "start_time": "2023-11-21T02:09:05.586342200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 0.999999\n",
    "\n",
    "def predict(model, ch):\n",
    "\n",
    "    # only look at last sample_len - 1 characters\n",
    "\n",
    "    ch = ch[-(sample_len - 1):]\n",
    "\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    ch = np.array([char2int(c) for c in ch])\n",
    "    ch = np.array([int2OneHot(ch, num_chars)])\n",
    "    ch = torch.from_numpy(ch).to(device)\n",
    "\n",
    "    out = model(ch)\n",
    "\n",
    "    # take the probability distribution of the last character in the sequence produced by the model\n",
    "    prob = softmax_with_temperature(out[-1],temperature)\n",
    "\n",
    "    # Choosing a character based on the probability distribution, with temperature\n",
    "    char_ind = choice(list(range(num_chars)), p=prob)\n",
    "\n",
    "    return int2char(char_ind)\n",
    "\n",
    "predict(model,\"public static void main(String\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:05.664478300Z",
     "start_time": "2023-11-21T02:09:05.606343100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample(model, out_len, start):\n",
    "    model.eval() # eval mode\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:09:11.158447600Z",
     "start_time": "2023-11-21T02:09:05.650515500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public static void main(String[] args) {   \n",
      "      \n",
      "      Scanner user = new Scanner(System.in);\n",
      "      int[][] a = new int[3][3];\n",
      "      \n",
      "      System.out.println(\"Welcome to the Eight-Puzzle Solver\");\n",
      "      System.out.println(\"Please input 9 digits (0--8) to\");  \n",
      "      System.out.println(\"specify the initial position\n",
      "         return reverseHelper(p, null);\n",
      "   }\n",
      "   \n",
      "   public static Node reverseHelper(Node p, Node q) {          // p is a stack that we pop from, and q a stack werue, een next v Node p ) {\n",
      "    if( p == null )                        // not in the list, insert at end\n",
      "      return new Node( k,d ); \n",
      "    else if( p.item == k ) {               // don't insert duplicates\n",
      "         return true;\n",
      "      else \n",
      "         return member( k, p.next ); \n",
      "   }\n",
      "   \n",
      "   \n",
      "   // returns the prime number just larger than p, or -1 hilun to left, 1     t                }\n",
      "                \n",
      "                // Shift right to make room for element.\n",
      "                int j = i;\n",
      "                do {\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "print(sample(model, 1000, \"public static void main(String[] args)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnB5z-ZoZEa5"
   },
   "source": [
    "### Your analysis\n",
    "\n",
    "Please describe your experiments and cut and paste various outputs to show how the model performed at\n",
    "various numbers of epochs and with various hyperparameters. What characteristics of Java was it able to learn? What did it not learn? The article \"The Unreasonable ...\" does a nice job of showing this kind of behavior as the number of epochs increases, and you might look at it before writing your answer here. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two:  Word-Level Generative Model (40 pts)\n",
    "\n",
    "In this problem you will write another generative model, as you did in HW 03, but this time you will use an LSTM network, GloVe word embeddings, and beam search. \n",
    "\n",
    "Before you start, read the following blog post to see the core ideas involved in creating a generative model using word embeddings:\n",
    "\n",
    "https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/\n",
    "\n",
    "You may also wish to consult with chatGPT about how to develop this kind of model in Pytorch.\n",
    "\n",
    "The requirements for this problem are as follows (they mostly consist of the extensions proposed at\n",
    "the end of the blog post linked above):\n",
    "\n",
    "- Develop your code in Pytorch, not Keras\n",
    "- Use the novel *Persuation* by Jane Austen as your training data (available through the Brown Corpus); if you have trouble with RAM you will need to cut down the number of sentences (perhaps by eliminating the longest sentences as well, see next point). \n",
    "- Develop a sentence-level model by padding sentences to the maximum sentence length in the novel (if this seems extreme, you may wish to delete a small number of the longest sentences to reduce the maximum length). Surround your data sentences with `<s>` and `</s>` and your model should generate one sentence at a time (as you did in HW 03), i.e., it should stop if it generates the `</s>` token. \n",
    "- Use pretrained GLoVe embeddings with dimension 200, and update them (refine by training further) on the sentences in the novel; if you have trouble with RAM you may use a smaller dimension. \n",
    "- Experiment with the hyperparameters (sample length, number of layers, uni- or bi-directional, weight_decay, dropout, number of epochs, temperature of the softmax, etc.) as you did in Problem One to find the \"sweet spot\" where you are generating interesting-looking sentences but not simply repeating sentences from the data. You may want to try adding more linear layers on top to pick the most likely next word. \n",
    "- Generate sentences using Beam Search, which we describe below. \n",
    "\n",
    "Your solution should be the code, samples of sentences generated with their score (described below), and your description of the investigation of various hyperparameters, and what strategy ended up seeming to generate the most realistic sentences that were not simply a repeat of sentences in the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:55:19.120832200Z",
     "start_time": "2023-11-21T02:55:07.077007300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /usr4/cs505ws/aseef/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#if does_var_exists('persuasion_doc'):\n",
    "#    persuasion_doc = load_var('persuasion_doc')\n",
    "#else:\n",
    "# download it from gutenberg\n",
    "nltk.download('gutenberg')\n",
    "# Load the text of Persuasion by Jane Austen\n",
    "persuasion_raw_text = gutenberg.raw('austen-persuasion.txt')\n",
    "# Tokenize the text into sentences\n",
    "#spacy.require_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "persuasion_doc = nlp(persuasion_raw_text)\n",
    "dump_var('persuasion_doc', persuasion_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:55:30.516345400Z",
     "start_time": "2023-11-21T02:55:30.475246300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert doc to a string list of sentences\n",
    "persuasion_sentences: List[List[str]] = []\n",
    "for sent in persuasion_doc.sents:\n",
    "    persuasion_sentences += [sent.__str__()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:55:31.227808900Z",
     "start_time": "2023-11-21T02:55:31.210797Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Persuasion by Jane Austen 1818]\n",
      "\n",
      "\n",
      "Chapter 1\n",
      "\n",
      "\n",
      "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
      "for his own amusement, never took up any book but the Baronetage;\n",
      "there he found occupation for an idle hour, and consolation in a\n",
      "distressed one; there his faculties were roused into admiration and\n",
      "respect, by contemplating the limited remnant of the earliest patents;\n",
      "there any unwelcome sensations, arising from domestic affairs\n",
      "changed naturally into pity and contempt as he turned over\n",
      "the almost endless creations of the last century; and there,\n",
      "if every other leaf were powerless, he could read his own history\n",
      "with an interest which never failed.  \n",
      "This was the page at which\n",
      "the favourite volume always opened:\n",
      "\n",
      "           \"ELLIOT OF KELLYNCH HALL.\n",
      "\n",
      "\n",
      "\"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth,\n",
      "daughter of James Stevenson, Esq. of South Park, in the county of\n",
      "Gloucester, by which lady (who died 1800) he has issue Elizabeth,\n",
      "born June 1, 1785; Anne, born August 9, 1787; a still-born son,\n",
      "November 5, 1789; Mary, born November 20, 1791.\n"
     ]
    }
   ],
   "source": [
    "# print first 3 sentences to confirm stuff works\n",
    "for sent in persuasion_sentences[:3]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:55:32.220558400Z",
     "start_time": "2023-11-21T02:55:32.205555200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>this was the page at which\n",
      "the favourite volume always opened:\n",
      "\n",
      "           \"elliot of kellynch hall.</s>\n",
      "<s>\"walter elliot, born march 1, 1760, married, july 15, 1784, elizabeth,\n",
      "daughter of james stevenson, esq. of south park, in the county of\n",
      "gloucester, by which lady (who died 1800) he has issue elizabeth,\n",
      "born june 1, 1785; anne, born august 9, 1787; a still-born son,\n",
      "november 5, 1789; mary, born november 20, 1791.</s>\n",
      "<s>\"\n",
      "\n",
      "precisely such had the paragraph originally stood from the printer's hands;\n",
      "but sir walter had improved it by adding, for the information of\n",
      "himself and his family, these words, after the date of mary's birth--\n",
      "\"married, december 16, 1810, charles, son and heir of charles\n",
      "musgrove, esq. of uppercross, in the county of somerset,\"\n",
      "and by inserting most accurately the day of the month on which\n",
      "he had lost his wife.</s>\n",
      "<s>then followed the history and rise of the ancient and respectable family,\n",
      "in the usual terms; how it had been first settled in cheshire;\n",
      "how mentioned in dugdale, serving the office of high sheriff,\n",
      "representing a borough in three successive parliaments,\n",
      "exertions of loyalty, and dignity of baronet, in the first year\n",
      "of charles ii, with all the marys and elizabeths they had married;\n",
      "forming altogether two handsome duodecimo pages, and concluding with\n",
      "the arms and motto:--\"principal seat, kellynch hall, in the county\n",
      "of somerset,\" and sir walter's handwriting again in this finale:--\n",
      "\n",
      "\"heir presumptive, william walter elliot, esq., great grandson of\n",
      "the second sir walter.</s>\n",
      "<s>\"\n",
      "\n",
      "vanity was the beginning and the end of sir walter elliot's character;\n",
      "vanity of person and of situation.</s>\n"
     ]
    }
   ],
   "source": [
    "# lets clean up the sentences...\n",
    "persuasion_cleaned_sentences = persuasion_sentences\n",
    "# 1. get rid of the book title\n",
    "persuasion_cleaned_sentences: List[str] = persuasion_cleaned_sentences[1:]\n",
    "# 2. get rid of chapter titles\n",
    "for i in range(len(persuasion_cleaned_sentences)):\n",
    "    persuasion_cleaned_sentences[i] = re.sub(\"Chapter [0-9]+\", \"\", persuasion_cleaned_sentences[i])\n",
    "# 3. get rid of trailing whitespaces\n",
    "for i in range(len(persuasion_cleaned_sentences)):\n",
    "    persuasion_cleaned_sentences[i] = persuasion_cleaned_sentences[i].strip()\n",
    "# 4. lowercase everything\n",
    "for i in range(len(persuasion_cleaned_sentences)):\n",
    "    persuasion_cleaned_sentences[i] = persuasion_cleaned_sentences[i].lower()\n",
    "# 5. Surround your data sentences with `<s>` and `</s>`\n",
    "for i in range(len(persuasion_cleaned_sentences)):\n",
    "    persuasion_cleaned_sentences[i] = \"<s>\" + persuasion_cleaned_sentences[i] + \"</s>\"\n",
    "\n",
    "# print a few sents to make sure everything looks good\n",
    "for sent in persuasion_cleaned_sentences[:5]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:55:33.037878500Z",
     "start_time": "2023-11-21T02:55:32.995844600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5f51f46146ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove2word2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the glove models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this actually takes a while so ill save the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdoes_var_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mF'glove_model_200d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "# load the glove models\n",
    "# this actually takes a while so ill save the result\n",
    "if does_var_exists(F'glove_model_200d'):\n",
    "    glove_model = load_var(F'glove_model_200d')\n",
    "else:\n",
    "    glove_dataset_dir = F'./data/glove/glove.6B.200d.txt'\n",
    "    glove_output_vec_dir = F'./data/glove/glove.6B.200d.wv'\n",
    "    if not os.path.isfile(glove_output_vec_dir):\n",
    "        glove2word2vec(glove_dataset_dir, glove_output_vec_dir)\n",
    "    glove_model = KeyedVectors.load_word2vec_format(glove_output_vec_dir, binary=False)\n",
    "    dump_var(F'glove_model_200d', glove_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnB5z-ZoZEa5"
   },
   "source": [
    "### Beam Search\n",
    "\n",
    "Beam search was described, and example shown, in Lecture 14. Here is a brief pseudo-code explaination of what\n",
    "you need to do:\n",
    "\n",
    "1. Develop your code as described above so that it can generate single sentences;\n",
    "2. Copy enough of your code over from HW 03 so that you can calculate the perplexity of\n",
    "        sentences (using the entire novel, or perhaps even a number of Jane Austen's novels as\n",
    "        the data source). As an alternative, you may wish to do this separately, store the nested dictionary\n",
    "        using Pickle, and load it here. \n",
    "3. Calculate the probability distribution of sentences in your data source that you used in the previous step, similar to what you did at the end of HW 01. \n",
    "4. Create a \"goodness function\" which estimates the quality of a sentence as the perplexity times the probability of its length.  This will be applied to all sequences of words, and not just sentences, but as a first approximation this is a way to attempt to make the distribution of sentence lengths similar to that in the novel.\n",
    "5. Follow the description in slide 7 of Lecture 14 to generate until you have 10 finished sentences. Print these out with their perplexity, probability of their length, and the combined goodness metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:54:24.446804200Z",
     "start_time": "2023-11-21T01:54:24.436803900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Describe what experiments you did with various alternatives as described above, and cut and paste examples illustrating your results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three:  Part-of-Speech Tagging (40 pts)\n",
    "\n",
    "In this problem, we will experiment with three different approaches to the POS tagging problem, using\n",
    "the Brown Corpus as our data set. \n",
    "\n",
    "Before starting this problem, please review Lecture 13 and download the file <a href=\"Viterbi.ipynb\">Viterbi.ipynb</a> from the \n",
    "class web site. \n",
    "\n",
    "There are four parts to this problem:\n",
    "\n",
    "- Part A: You will establish a baseline accuracy for the task. \n",
    "- Part B: Using the implementation of the Viterbi algorithm for Hidden Markov Models you downloaded, you will determine how much better than the baseline you can do with this very standard method.\n",
    "- Part C: You will repeat the exercise of Part B, but using an LSTM implementation, exploring several options for the implementation of the LSTM layer.\n",
    "- Part D: You will evaluate your results, comparing the various methods in the context of the baseline method from Part A.\n",
    "- Optional: You may wish to try the same task with a transformer such as Bert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Brown Corpus has a list of all sentences tagged with parts of speech. The tags are\n",
    "a bit odd, and not generally used any more, so we will use a much simpler set of tags the `universal_tagset`. \n",
    "\n",
    "If you run the following cells, you will see that there are 57,340 sentences, tagged with 12 different tags. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:54:27.572966900Z",
     "start_time": "2023-11-21T01:54:24.436803900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /usr4/cs505ws/aseef/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /usr4/cs505ws/aseef/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences tagged with universal POS tags in the Brown Corpus.\n",
      "\n",
      "Here is the first sentence with universal tags: [('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# The first time you will need to download the corpus:\n",
    "\n",
    "from nltk.corpus import brown\n",
    " \n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "tagged_sentences = brown.tagged_sents(tagset='universal')\n",
    "\n",
    "print(f'There are {len(tagged_sentences)} sentences tagged with universal POS tags in the Brown Corpus.')\n",
    "print(\"\\nHere is the first sentence with universal tags:\",tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:54:34.835936Z",
     "start_time": "2023-11-21T01:54:27.574967900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 universal tags in the Brown Corpus.\n",
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to see the complete list of tags. \n",
    "\n",
    "all_tagged_words = np.concatenate(tagged_sentences)\n",
    "all_tags = sorted(set([pos for (w,pos) in all_tagged_words]))\n",
    "print(f'There are {len(all_tags)} universal tags in the Brown Corpus.')\n",
    "print(all_tags)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnB5z-ZoZEa5"
   },
   "source": [
    "### Part A\n",
    "\n",
    "In this part, you will establish a baseline for the task, using the naive method suggested on slide 35 of Lecture 13:\n",
    "\n",
    "- Tag every word with its most frequent POS tag (for example, if 'recent' is most frequently tagged as 'ADJ', then assume that every time 'recent' appears in a sentence, it should be tagged with 'ADJ'); \n",
    "- If a word has two or more most frequent tags, choose the one that appears first in the list of sorted tags above. \n",
    "\n",
    "Note that there will not be any \"unknown words.\" \n",
    " \n",
    "Use this method to determine your baseline accuracy (it may not be 92% as reported on slide 35!):\n",
    "\n",
    "- Build a dictionary mapping every word to its most frequent tag;\n",
    "- Go through the entire tagged corpus, and report the accuracy (percentage of correct tags) of this baseline method. \n",
    "\n",
    "Do not tokenize or lower-case the words. Use the words and tags exactly as they are in the tagged sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B:  \n",
    "\n",
    "Now, review the `Viterbi.ipynb` notebook and read through Section 8.4 in Jurafsky & Martin to understand the basic approach that is used in the \"Janet will back the bill\" example. In detail:\n",
    "\n",
    "- Cut and paste the code from the Viterby notebook below and run your experiments in this notebook. \n",
    "- You need to calculate from the Brown Corpus tagged sentences the probabilities for the various matrices used as input to the method:\n",
    "   - `start_p`: This is the probability that a sentence starts with a given POS (in Figure 8.12 in J & M, this is given as the first line, in the row for `<s>`; simply collect the statistics for the first word in each sentence; it will be of size 1 x 12. \n",
    "   - `trans_p`: This is the matrix of probabilities that one POS follows another in a sentence; build a 12 x 12 matrix of frequencies for whether the column POS follows the row POS in a sentence and then normalize each row so that it is a probability distribution (each row should add to 1.0)\n",
    "   - `emit_p`: This is a matrix of size 12 x N, where N is the number of unique words in the corpus, which for each POS (the row) gives the probability that this POS in the output sequence corresponds to a specific word (the column) in the input sequence; again, you should collect frequency statistics about the relationship between POS and words, and normalize so that every row sums to 1.0. \n",
    "   \n",
    "Then run the algorithm on all the sentences in the tagged corpus, and determine the accuracy of the Viterbi algorithm. Again, the accuracy is calculated on each word, not on sentences as a whole. \n",
    "\n",
    "Report your results as a raw accuracy score, and in the two ways that were suggested on slide 12 of Lecture 11: percentage above the baseline established in Part A, and Cohen's Kappa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T01:54:34.844973300Z",
     "start_time": "2023-11-21T01:54:34.839932300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Viterbi code should be pasted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C:  \n",
    "\n",
    "Next, you will need to develop an LSTM model to solve this problem. You may find it useful to\n",
    "refer to the following, which presents an approach in Keras.\n",
    "\n",
    "https://www.kaggle.com/code/tanyadayanand/pos-tagging-using-rnn/notebook\n",
    "\n",
    "\n",
    "You must do the following for this part:\n",
    "\n",
    "- Develop your code in Pytorch (of course!);\n",
    "- Use pretrained GloVe embeddings of dimension 200 and update them with the brown sentences; if you run into problems with RAM, you may use a smaller embedding dimension; \n",
    "- Truncate all sentences to a maximum of length 100 tokens, and pad shorter sentences (as in the reference above);\n",
    "- Use an LSTM model and try several different choices for the parameters to the layer:\n",
    "  - `hidden_size`:  Try several different widths for the layer\n",
    "  - `bidirectional`: Try unidirectional (False) and bidirectional (True)\n",
    "  - `num_layers`: Try 1 layer and 2 layers\n",
    "  - `dropout`: In the case of 2 layers, try several different dropouts, including 0.\n",
    "- Use early stopping with `patience = 50`;  \n",
    "You do not have to try every possible combination of these parameter choices; a good strategy is to\n",
    "try them separately, and then try a couple of combinations of the best choices of each. \n",
    "\n",
    "It is your choice about the other hyperparameters.  \n",
    "\n",
    "Provide a brief discussion of what you discovered, your best loss and accuracy measures for\n",
    "validation, and three versions of your testing accuracy, as in Part B.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide an analysis of what experiments you conducted with hyperparameters, what your results were, and in particular comment on how the two methods compare, especially given that one has *no* choice of hyperparameters, and one has *many* choices of parameters. How useful was the flexibility of choice in hyperparameters in Part C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional:\n",
    "\n",
    "You might want to try doing this problem with a transformer model such as BERT. There are plenty of blog posts out there describing the details, and, as usual, chatGPT would have plenty of things to say about the topic.... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
